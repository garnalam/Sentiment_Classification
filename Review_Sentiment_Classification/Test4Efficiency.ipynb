{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "t8LBFyKf2azj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import underthesea\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "rPTvyZJ93fBO"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/Dataset_For_Work\"\n",
        "test_data_1 = \"/content/drive/MyDrive/Dataset_For_Work/test_raw_ANS.txt\"\n",
        "test_data_2 = \"/content/drive/MyDrive/Dataset_For_Work/test_tokenized_ANS.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "n-zFl-OI3juc"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path, label):\n",
        "    \"\"\"\n",
        "    Đọc dữ liệu từ file và gắn nhãn tương ứng.\n",
        "    Args:\n",
        "        file_path (str): Đường dẫn đến tệp văn bản.\n",
        "        label (str): Nhãn cảm xúc (positive, neutral, negative).\n",
        "    Returns:\n",
        "        data (list): Danh sách chứa các câu và nhãn.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            sentence = line.strip()  # Xóa khoảng trắng ở đầu và cuối câu\n",
        "            if sentence:  # Chỉ thêm những câu không rỗng\n",
        "                data.append((sentence, label))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "JiuKSFtJsbAT"
      },
      "outputs": [],
      "source": [
        "def load_test(file_path):\n",
        "    \"\"\"\n",
        "    Đọc dữ liệu từ file và gắn nhãn cảm xúc từ chuỗi đã cho.\n",
        "    Args:\n",
        "        file_path (str): Đường dẫn đến tệp văn bản.\n",
        "    Returns:\n",
        "        data (list): Danh sách chứa các câu và nhãn tương ứng.\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    data = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text = file.read()  # Đọc toàn bộ nội dung file\n",
        "        split_data = re.split(r'(POS|NEG|NEU)', text.strip())  # Tách dữ liệu theo nhãn\n",
        "        for i in range(0, len(split_data) - 1, 2):  # Lặp qua từng cặp câu và nhãn\n",
        "            sentence = split_data[i].strip()  # Xóa khoảng trắng ở đầu và cuối câu\n",
        "            label = split_data[i + 1]  # Lấy nhãn tương ứng\n",
        "            if sentence:  # Chỉ thêm những câu không rỗng\n",
        "                data.append((sentence, label))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "m2WbvQyI3mAM"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Làm sạch văn bản bằng cách loại bỏ ký tự đặc biệt, số và khoảng trắng thừa.\n",
        "    Args:\n",
        "        text (str): Câu văn bản cần làm sạch.\n",
        "    Returns:\n",
        "        str: Văn bản sau khi làm sạch.\n",
        "    \"\"\"\n",
        "    text = text.lower()  # Chuyển thành chữ thường\n",
        "    text = re.sub(r'\\d+', '', text)  # Loại bỏ số\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Loại bỏ khoảng trắng thừa\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ND_DdT5Zszig"
      },
      "outputs": [],
      "source": [
        "from underthesea import word_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "# Load stopwords from file\n",
        "stop_words_path = \"/content/drive/MyDrive/Dataset_For_Work/vietnamese-stopwords.txt\"\n",
        "\n",
        "with open(stop_words_path, 'r', encoding='utf-8') as f:\n",
        "    stop_words = set(f.read().splitlines())\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(sentence):\n",
        "    # Tokenize and filter stopwords\n",
        "    word_tokens = word_tokenize(sentence)\n",
        "    filtered_words = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Function to map sentiment labels\n",
        "def replace_labels(label):  # Changed here: removed 'df' and kept 'label_column'\n",
        "    sentiment_map = {'POS': 1, 'NEG': -1, 'NEU': 0}\n",
        "    return sentiment_map.get(label, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG5frxPq31lI",
        "outputId": "72d6e0ef-4449-4f89-ddb0-1ffc5883ee48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence Label\n",
            "0  đang xài mx dùng bình thường ngon pin trâu mỗi...   POS\n",
            "1  qủa pin ngon sạc lại được bền riêng em dùng pi...   POS\n",
            "2  cũng đang xài con logitech bluetooth tầm thấp ...   POS\n",
            "3  logitech pin trâu thôi rôi mua con b cui ma cu...   POS\n",
            "4  em có con chuột không dây k cũng đầy đủ nút bấ...   POS\n"
          ]
        }
      ],
      "source": [
        "# Đọc dữ liệu từ các tệp và gắn nhãn\n",
        "positive_data = load_data(os.path.join(data_path, \"SA-training_positive.txt\"), \"POS\")\n",
        "neutral_data = load_data(os.path.join(data_path, \"SA-training_neutral.txt\"), \"NEU\")\n",
        "negative_data = load_data(os.path.join(data_path, \"SA-training_negative.txt\"), \"NEG\")\n",
        "\n",
        "# Kết hợp tất cả dữ liệu\n",
        "all_data = positive_data + neutral_data + negative_data\n",
        "\n",
        "# Tiền xử lý văn bản\n",
        "cleaned_data = [(clean_text(sentence), label) for sentence, label in all_data]\n",
        "\n",
        "# Chuyển dữ liệu sang DataFrame\n",
        "df = pd.DataFrame(cleaned_data, columns=[\"Sentence\", \"Label\"])\n",
        "\n",
        "# Hiển thị một vài dòng đầu tiên\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oxhiRZHtUO8",
        "outputId": "a9664ef7-fde0-4a82-815b-2a0e0e866d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence Label\n",
            "0  không nên mua chuột cua logitech vì dùng nó rấ...   POS\n",
            "1  nói thiệt là mình thì thì chuột nào mình cũng ...   NEG\n",
            "2                  xai chuot so nhat bi double click   NEU\n",
            "3  cơ bản là thiết kế ôm chuột chưa đã như hiện g...   POS\n",
            "4  đang dùng mx cũng ngon nhưng chưa đầy năm mà đ...   NEG\n"
          ]
        }
      ],
      "source": [
        "test = load_test(test_data_1)\n",
        "cleaned_data = [(clean_text(sentence), label) for sentence, label in test]\n",
        "tf1 = pd.DataFrame(cleaned_data, columns=[\"Sentence\", \"Label\"])\n",
        "print(tf1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v24bAn-3YtMk",
        "outputId": "96bd3945-24fd-4a0f-c2c3-a3c976dbb210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence Label\n",
            "0  không nên mua chuột cua logitech vì dùng nó rấ...   POS\n",
            "1  nói thiệt là mình thì thì chuột nào mình cũng ...   NEG\n",
            "2                  xai chuot so nhat bi double_click   NEU\n",
            "3  cơ_bản là thiết_kế ôm chuột chưa đã như hiện_g...   POS\n",
            "4  đang dùng mx_ cũng ngon nhưng chưa đầy_năm mà ...   NEG\n"
          ]
        }
      ],
      "source": [
        "test = load_test(test_data_2)\n",
        "cleaned_data = [(clean_text(sentence), label) for sentence, label in test]\n",
        "tf2 = pd.DataFrame(cleaned_data, columns=[\"Sentence\", \"Label\"])\n",
        "print(tf2.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d210Eimm3pjM",
        "outputId": "f1201584-9a08-4670-85c6-17c09e2486fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dữ liệu sau khi xử lý:\n",
            "                                            Sentence  Label\n",
            "0  xài mx bình thường ngon pin trâu tội thằng chỗ...      1\n",
            "1               pin ngon sạc bền pin aa aaa thay thế      1\n",
            "2      xài logitech bluetooth tầm m xài đc ngon chán      1\n",
            "3  logitech pin trâu thôi rôi mua b cui ma cuc pi...      1\n",
            "4                chuột dây k đầy đủ nút bấm pin thay      1\n"
          ]
        }
      ],
      "source": [
        "df['Sentence'] = df['Sentence'].apply(remove_stopwords)\n",
        "df['Label'] = df['Label'].apply(replace_labels)\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(\"Dữ liệu sau khi xử lý:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7NOYaWVvZBU",
        "outputId": "e2533ada-6e4a-45b5-b15d-e6875248eb81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dữ liệu sau khi xử lý:\n",
            "                                            Sentence  Label\n",
            "0  mua chuột cua logitech đổi thằng xúi mua m cơ ...      1\n",
            "1  thiệt chuột tuốt trừ hãng razer sở hữu da blac...     -1\n",
            "2                     xai chuot nhat bi double click      0\n",
            "3  cơ bản thiết kế ôm chuột hiện giờ chuột hàng n...      1\n",
            "4              mx ngon tháo thay nút bấm may lột máy     -1\n"
          ]
        }
      ],
      "source": [
        "tf1['Sentence'] = tf1['Sentence'].apply(remove_stopwords)\n",
        "tf1['Label'] = tf1['Label'].apply(replace_labels)\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(\"Dữ liệu sau khi xử lý:\")\n",
        "print(tf1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3LA9PBiY_O1",
        "outputId": "3cea6ca3-3c40-4bd5-ded4-c522d98a93af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dữ liệu sau khi xử lý:\n",
            "                                            Sentence  Label\n",
            "0  mua chuột cua logitech đổi thằng xúi mua m cơ_...      1\n",
            "1  thiệt chuột tuốt trừ hãng razer sở_hữu da blac...     -1\n",
            "2                     xai chuot nhat bi double_click      0\n",
            "3  cơ_bản thiết_kế ôm chuột hiện_giờ chuột hàng n...      1\n",
            "4     mx_ ngon đầy_năm tháo thay nút bấm may lột máy     -1\n"
          ]
        }
      ],
      "source": [
        "tf2['Sentence'] = tf2['Sentence'].apply(remove_stopwords)\n",
        "tf2['Label'] = tf2['Label'].apply(replace_labels)\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(\"Dữ liệu sau khi xử lý:\")\n",
        "print(tf2.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "MDuSb8Yq6rH3"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "# Chuẩn bị dữ liệu cho Word2Vec\n",
        "# Mỗi câu cần được token hóa thành danh sách từ\n",
        "tokenized_sentences = df['Sentence'].apply(word_tokenize).tolist()\n",
        "\n",
        "# Huấn luyện mô hình Word2Vec\n",
        "word2vec_model = Word2Vec(\n",
        "    sentences=tokenized_sentences,  # Câu đã được token hóa\n",
        "    vector_size=100,               # Kích thước vector\n",
        "    window=5,                      # Kích thước cửa sổ ngữ cảnh\n",
        "    min_count=1,                   # Bỏ qua từ xuất hiện ít hơn 1 lần\n",
        "    sg=1,                          # Sử dụng Skip-Gram (0 cho CBOW)\n",
        "    epochs=10                      # Số lần huấn luyện\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrJpNxSV8SMq",
        "outputId": "16c68273-6c1c-40b8-f1fe-db38cc25561f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector của từ 'pin': [ 1.99249506e-01 -4.36593294e-02 -2.01470807e-01  1.06672794e-01\n",
            "  2.25676030e-01 -4.73399967e-01  4.41484362e-01  4.43093687e-01\n",
            " -1.73236012e-01 -7.59447813e-02  1.57781884e-01 -4.06754613e-01\n",
            " -2.79064655e-01  4.87020910e-02 -2.33623505e-01 -2.21857816e-01\n",
            "  4.09822226e-01 -6.14179969e-02 -2.50109434e-01 -5.67974031e-01\n",
            " -1.65379883e-04  1.60138056e-01  2.62542725e-01 -9.03877318e-02\n",
            " -9.54064578e-02  1.30866066e-01  3.22116278e-02 -2.74598032e-01\n",
            " -1.01372883e-01 -1.28232017e-01  4.15105700e-01  3.15618545e-01\n",
            "  3.47024687e-02 -2.09962666e-01 -3.03575754e-01  7.37473890e-02\n",
            "  1.36246011e-01 -3.65353376e-01  1.77255854e-01 -7.60315835e-01\n",
            "  5.00463367e-01 -4.26257640e-01  3.33881110e-01 -2.06038311e-01\n",
            "  4.96722400e-01  5.84370375e-01 -3.74880552e-01 -2.38962412e-01\n",
            " -5.65280579e-02  7.44526908e-02 -1.38454348e-01 -3.19362551e-01\n",
            " -2.01504722e-01  1.49517730e-01 -3.17633480e-01 -1.82407070e-02\n",
            "  2.16003031e-01 -1.26213506e-01 -3.64194661e-01  6.70154244e-02\n",
            "  3.72562706e-02  5.04522212e-02  8.65498558e-02  4.49466966e-02\n",
            " -4.06601727e-01  3.87961864e-01 -1.11358963e-01  2.03284815e-01\n",
            " -5.92999578e-01  2.98105597e-01 -2.96335340e-01  5.29112527e-04\n",
            "  4.03045803e-01  4.09258783e-01  4.17087555e-01 -3.50880772e-01\n",
            "  1.95679158e-01  2.87542050e-03 -3.16074163e-01  5.12314476e-02\n",
            " -1.23351170e-02 -5.35259604e-01 -3.12842846e-01  5.62726200e-01\n",
            " -4.74429309e-01 -9.53770578e-02  3.38959455e-01 -2.45989114e-01\n",
            " -3.00485611e-01 -1.70256257e-01  1.75010905e-01  2.12751642e-01\n",
            "  1.20100066e-01 -1.11123726e-01  2.23385721e-01  8.19292739e-02\n",
            "  8.19811076e-02 -3.06908846e-01  1.72716811e-01  3.08834631e-02]\n"
          ]
        }
      ],
      "source": [
        "# Lấy vector của từ \"khách_sạn\"\n",
        "word_vector = word2vec_model.wv['pin']\n",
        "print(\"Vector của từ 'pin':\", word_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ZaIxiel_88iH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sentence_to_vector(sentence, model):\n",
        "    # Tokenize câu\n",
        "    tokens = word_tokenize(sentence)\n",
        "    # Lấy vector của từng từ, nếu từ không tồn tại trong từ điển thì bỏ qua\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    # Tính trung bình các vector từ\n",
        "    if len(vectors) > 0:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)  # Vector rỗng nếu không có từ hợp lệ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDDW2BPILIV2",
        "outputId": "6aebbe05-6fd4-4ed9-9269-b6656654c3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence  Label  \\\n",
            "0  xài mx bình thường ngon pin trâu tội thằng chỗ...      1   \n",
            "1               pin ngon sạc bền pin aa aaa thay thế      1   \n",
            "2      xài logitech bluetooth tầm m xài đc ngon chán      1   \n",
            "3  logitech pin trâu thôi rôi mua b cui ma cuc pi...      1   \n",
            "4                chuột dây k đầy đủ nút bấm pin thay      1   \n",
            "\n",
            "                                     Sentence_Vector  \n",
            "0  [0.052804887, 0.06910979, -0.14952543, 0.02957...  \n",
            "1  [0.06292388, 0.028278971, -0.10335348, 0.01718...  \n",
            "2  [0.12708806, 0.14319688, -0.18849689, 0.043886...  \n",
            "3  [0.06200254, 0.08732359, -0.099150985, 0.03169...  \n",
            "4  [0.018859807, 0.08623658, -0.09054096, 0.06014...  \n"
          ]
        }
      ],
      "source": [
        "# Biểu diễn toàn bộ tập dữ liệu\n",
        "df['Sentence_Vector'] = df['Sentence'].apply(lambda x: sentence_to_vector(x, word2vec_model))\n",
        "\n",
        "# Hiển thị một vài dòng đầu tiên\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wVg1HTFxde2",
        "outputId": "bd09b57f-66bb-4861-aa02-02262c442263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence  Label  \\\n",
            "0  mua chuột cua logitech đổi thằng xúi mua m cơ ...      1   \n",
            "1  thiệt chuột tuốt trừ hãng razer sở hữu da blac...     -1   \n",
            "2                     xai chuot nhat bi double click      0   \n",
            "3  cơ bản thiết kế ôm chuột hiện giờ chuột hàng n...      1   \n",
            "4              mx ngon tháo thay nút bấm may lột máy     -1   \n",
            "\n",
            "                                     Sentence_Vector  \n",
            "0  [0.034310948, 0.12954247, -0.10234582, 0.06872...  \n",
            "1  [0.020708924, 0.104175724, -0.10100166, 0.0522...  \n",
            "2  [0.05503485, 0.1231741, -0.03557769, 0.0169322...  \n",
            "3  [0.019779623, 0.12602726, -0.2025885, 0.018201...  \n",
            "4  [0.01128612, 0.10690278, -0.061254647, 0.00831...  \n"
          ]
        }
      ],
      "source": [
        "# Biểu diễn toàn bộ tập dữ liệu\n",
        "tf1['Sentence_Vector'] = tf1['Sentence'].apply(lambda x: sentence_to_vector(x, word2vec_model))\n",
        "\n",
        "# Hiển thị một vài dòng đầu tiên\n",
        "print(tf1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwkn7i-Favpu",
        "outputId": "5f2378e2-058d-45f6-b7b0-303cdabd71cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence  Label  \\\n",
            "0  mua chuột cua logitech đổi thằng xúi mua m cơ_...      1   \n",
            "1  thiệt chuột tuốt trừ hãng razer sở_hữu da blac...     -1   \n",
            "2                     xai chuot nhat bi double_click      0   \n",
            "3  cơ_bản thiết_kế ôm chuột hiện_giờ chuột hàng n...      1   \n",
            "4     mx_ ngon đầy_năm tháo thay nút bấm may lột máy     -1   \n",
            "\n",
            "                                     Sentence_Vector  \n",
            "0  [0.038315285, 0.15769373, -0.10229123, 0.09989...  \n",
            "1  [0.019190429, 0.10466096, -0.10188547, 0.04904...  \n",
            "2  [0.06594109, 0.13041188, -0.0096508395, 0.0139...  \n",
            "3  [0.009836002, 0.11983356, -0.16655947, 0.04892...  \n",
            "4  [0.011864754, 0.10820059, -0.074378096, 0.0155...  \n"
          ]
        }
      ],
      "source": [
        "# Biểu diễn toàn bộ tập dữ liệu\n",
        "tf2['Sentence_Vector'] = tf2['Sentence'].apply(lambda x: sentence_to_vector(x, word2vec_model))\n",
        "\n",
        "# Hiển thị một vài dòng đầu tiên\n",
        "print(tf2.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "H3kbISUA9K2v"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Train Word2Vec model\n",
        "def train_word2vec(reviews, vector_size=100, window=5, min_count=1):\n",
        "    tokenized_reviews = [review.split() for review in reviews]\n",
        "    w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=vector_size, window=window, min_count=min_count, sg=0)\n",
        "    return w2v_model\n",
        "\n",
        "# Step 2: Vectorize reviews\n",
        "def get_sentence_vector(sentence, model):\n",
        "    words = sentence.split()\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    if word_vectors:\n",
        "        return np.mean(word_vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "# Train Word2Vec model on sentences\n",
        "w2v_model = train_word2vec(df['Sentence'], vector_size=100)\n",
        "\n",
        "# Prepare training data\n",
        "X_train = [get_sentence_vector(sentence, w2v_model) for sentence in df['Sentence']]\n",
        "y_train = df['Label']\n",
        "\n",
        "# Fit Logistic Regression model\n",
        "classifier = RandomForestClassifier(n_estimators=100)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Prepare test data\n",
        "X_test_1 = [get_sentence_vector(sentence, w2v_model) for sentence in tf1['Sentence']]\n",
        "X_test_2 = [get_sentence_vector(sentence, w2v_model) for sentence in tf2['Sentence']]\n",
        "y_test_1 = tf1['Label']\n",
        "y_test_2 = tf2['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx1V-uIDZiZG",
        "outputId": "8df8e46e-c204-47e9-a5c5-9bb748b17c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.48\n",
            "\n",
            "Predictions Table:\n",
            "                                               Sentence True Label  \\\n",
            "0     mua chuột cua logitech đổi thằng xúi mua m cơ ...   Positive   \n",
            "1     thiệt chuột tuốt trừ hãng razer sở hữu da blac...   Negative   \n",
            "2                        xai chuot nhat bi double click    Neutral   \n",
            "3     cơ bản thiết kế ôm chuột hiện giờ chuột hàng n...   Positive   \n",
            "4                 mx ngon tháo thay nút bấm may lột máy   Negative   \n",
            "...                                                 ...        ...   \n",
            "1045                                    xấu khủng khiếp   Negative   \n",
            "1046     mẹ đài loan mua iphone plus i đổi máy chờ quen    Neutral   \n",
            "1047         tùng minh nguyễn điện thoại vk may cảm ứng    Neutral   \n",
            "1048  mua g bộ nhớ g ko thẻ yếu chụp ảnh game cân nh...   Negative   \n",
            "1049  sản phẩm gionee tốt minh dung s camera đêm ko ...   Positive   \n",
            "\n",
            "     Predicted Label  \n",
            "0            Neutral  \n",
            "1           Negative  \n",
            "2           Positive  \n",
            "3           Negative  \n",
            "4            Neutral  \n",
            "...              ...  \n",
            "1045        Positive  \n",
            "1046        Negative  \n",
            "1047         Neutral  \n",
            "1048         Neutral  \n",
            "1049        Positive  \n",
            "\n",
            "[1050 rows x 3 columns]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.45      0.47      0.46       350\n",
            "     Neutral       0.47      0.52      0.49       350\n",
            "    Positive       0.53      0.44      0.48       350\n",
            "\n",
            "    accuracy                           0.48      1050\n",
            "   macro avg       0.48      0.48      0.48      1050\n",
            "weighted avg       0.48      0.48      0.48      1050\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict labels for test data\n",
        "y_pred_1 = classifier.predict(X_test_1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_1, y_pred_1)\n",
        "\n",
        "# Display accuracy\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Create a table to display results\n",
        "results_df = pd.DataFrame({\n",
        "    'Sentence': tf1['Sentence'],\n",
        "    'True Label': y_test_1,\n",
        "    'Predicted Label': y_pred_1\n",
        "})\n",
        "\n",
        "# Map numeric labels to text (Optional)\n",
        "label_mapping = {1: 'Positive', -1: 'Negative', 0: 'Neutral'}\n",
        "results_df['True Label'] = results_df['True Label'].map(label_mapping)\n",
        "results_df['Predicted Label'] = results_df['Predicted Label'].map(label_mapping)\n",
        "\n",
        "# Display the table\n",
        "print(\"\\nPredictions Table:\")\n",
        "print(results_df)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_1, y_pred_1, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nm-H70JZnvz",
        "outputId": "d0e63cef-d0f3-4aba-9589-5d662e5340fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.45\n",
            "\n",
            "Predictions Table:\n",
            "                                               Sentence True Label  \\\n",
            "0     mua chuột cua logitech đổi thằng xúi mua m cơ_...   Positive   \n",
            "1     thiệt chuột tuốt trừ hãng razer sở_hữu da blac...   Negative   \n",
            "2                        xai chuot nhat bi double_click    Neutral   \n",
            "3     cơ_bản thiết_kế ôm chuột hiện_giờ chuột hàng n...   Positive   \n",
            "4        mx_ ngon đầy_năm tháo thay nút bấm may lột máy   Negative   \n",
            "...                                                 ...        ...   \n",
            "1045                                    xấu khủng_khiếp   Negative   \n",
            "1046  mẹ đài_loan mua iphone__plus i như_vậy đổi máy...    Neutral   \n",
            "1047  tùng_minh_nguyễn điện_thoại vk thế_nào may cảm...    Neutral   \n",
            "1048  mua g bộ_nhớ_trong g ko thẻ_nhớ điểm_yếu chụp ...   Negative   \n",
            "1049  sản_phẩm gionee tốt minh dung s_ camera đêm ko...   Positive   \n",
            "\n",
            "     Predicted Label  \n",
            "0            Neutral  \n",
            "1           Negative  \n",
            "2           Negative  \n",
            "3            Neutral  \n",
            "4            Neutral  \n",
            "...              ...  \n",
            "1045        Negative  \n",
            "1046        Negative  \n",
            "1047        Negative  \n",
            "1048        Positive  \n",
            "1049         Neutral  \n",
            "\n",
            "[1050 rows x 3 columns]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.42      0.39      0.40       350\n",
            "     Neutral       0.43      0.49      0.46       350\n",
            "    Positive       0.50      0.47      0.48       350\n",
            "\n",
            "    accuracy                           0.45      1050\n",
            "   macro avg       0.45      0.45      0.45      1050\n",
            "weighted avg       0.45      0.45      0.45      1050\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict labels for test data\n",
        "y_pred_2 = classifier.predict(X_test_2)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_2, y_pred_2)\n",
        "\n",
        "# Display accuracy\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Create a table to display results\n",
        "results_df = pd.DataFrame({\n",
        "    'Sentence': tf2['Sentence'],\n",
        "    'True Label': y_test_2,\n",
        "    'Predicted Label': y_pred_2\n",
        "})\n",
        "\n",
        "# Map numeric labels to text (Optional)\n",
        "label_mapping = {1: 'Positive', -1: 'Negative', 0: 'Neutral'}\n",
        "results_df['True Label'] = results_df['True Label'].map(label_mapping)\n",
        "results_df['Predicted Label'] = results_df['Predicted Label'].map(label_mapping)\n",
        "\n",
        "# Display the table\n",
        "print(\"\\nPredictions Table:\")\n",
        "print(results_df)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_2, y_pred_2, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
