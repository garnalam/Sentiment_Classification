{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EI4ugaloa769"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import underthesea\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "92WomLyYg9EG"
      },
      "outputs": [],
      "source": [
        "data_path = \"./Dataset_For_Work\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O8HNt-eZhAO9"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path, label):\n",
        "    \"\"\"\n",
        "    Đọc dữ liệu từ file và gắn nhãn tương ứng.\n",
        "    Args:\n",
        "        file_path (str): Đường dẫn đến tệp văn bản.\n",
        "        label (str): Nhãn cảm xúc (positive, neutral, negative).\n",
        "    Returns:\n",
        "        data (list): Danh sách chứa các câu và nhãn.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            sentence = line.strip()  # Xóa khoảng trắng ở đầu và cuối câu\n",
        "            if sentence:  # Chỉ thêm những câu không rỗng\n",
        "                data.append((sentence, label))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J_LbukIphFRd"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Làm sạch văn bản bằng cách loại bỏ ký tự đặc biệt, số và khoảng trắng thừa.\n",
        "    Args:\n",
        "        text (str): Câu văn bản cần làm sạch.\n",
        "    Returns:\n",
        "        str: Văn bản sau khi làm sạch.\n",
        "    \"\"\"\n",
        "    text = text.lower()  # Chuyển thành chữ thường\n",
        "    text = re.sub(r'\\d+', '', text)  # Loại bỏ số\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Loại bỏ khoảng trắng thừa\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBhQYsA8hKoW",
        "outputId": "f7a040d0-340c-49d1-cd76-00aeb227bd99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            Sentence     Label\n",
            "0  đang xài mx dùng bình thường ngon pin trâu mỗi...  positive\n",
            "1  qủa pin ngon sạc lại được bền riêng em dùng pi...  positive\n",
            "2  cũng đang xài con logitech bluetooth tầm thấp ...  positive\n",
            "3  logitech pin trâu thôi rôi mua con b cui ma cu...  positive\n",
            "4  em có con chuột không dây k cũng đầy đủ nút bấ...  positive\n"
          ]
        }
      ],
      "source": [
        "# Đọc dữ liệu từ các tệp và gắn nhãn\n",
        "positive_data = load_data(os.path.join(data_path, \"SA-training_positive.txt\"), \"positive\")\n",
        "neutral_data = load_data(os.path.join(data_path, \"SA-training_neutral.txt\"), \"neutral\")\n",
        "negative_data = load_data(os.path.join(data_path, \"SA-training_negative.txt\"), \"negative\")\n",
        "\n",
        "# Kết hợp tất cả dữ liệu\n",
        "all_data = positive_data + neutral_data + negative_data\n",
        "\n",
        "# Tiền xử lý văn bản\n",
        "cleaned_data = [(clean_text(sentence), label) for sentence, label in all_data]\n",
        "\n",
        "# Chuyển dữ liệu sang DataFrame\n",
        "df = pd.DataFrame(cleaned_data, columns=[\"Sentence\", \"Label\"])\n",
        "\n",
        "# Hiển thị một vài dòng đầu tiên\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from underthesea import word_tokenize\n",
        "\n",
        "# Tải file stopwords\n",
        "stop_words_path = \"./Dataset_For_Work/vietnamese-stopwords.txt\"\n",
        "\n",
        "with open(stop_words_path, 'r', encoding='utf-8') as f:\n",
        "    stop_words = set(f.read().splitlines())\n",
        "\n",
        "# Loại bỏ stopwords\n",
        "def remove_stopwords(sentence):\n",
        "    # Tokenize and filter stopwords\n",
        "    word_tokens = word_tokenize(sentence)\n",
        "    filtered_words = [word for word in word_tokens if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Thay mác label\n",
        "def replace_labels(df, label_column):\n",
        "    sentiment_map = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
        "    if label_column in df.columns:\n",
        "        df[label_column] = df[label_column].map(sentiment_map)\n",
        "\n",
        "df['Sentence'] = df['Sentence'].apply(remove_stopwords)\n",
        "replace_labels(df, 'label')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(\"Dữ liệu sau khi xử lý:\")\n",
        "print(df.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
